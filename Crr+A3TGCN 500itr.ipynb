{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9pvWIvqjjMvh"
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Apr 27 09:39:22 2018\n",
    "\n",
    "@author: lhfcitylab\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_result(test_result,test_label1,path):\n",
    "    ##all test result visualization\n",
    "    fig1 = plt.figure(figsize=(7,1.5))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "    a_pred = test_result[:,0]\n",
    "    a_true = test_label1[:,0]\n",
    "    plt.plot(a_pred,'r-',label='prediction')\n",
    "    plt.plot(a_true,'b-',label='true')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_all.jpg')\n",
    "#    plt.show()\n",
    "    ## oneday test result visualization\n",
    "    fig1 = plt.figure(figsize=(7,1.5))\n",
    "#    ax1 = fig1.add_subplot(1,1,1)\n",
    "    a_pred = test_result[0:96,0]\n",
    "    a_true = test_label1[0:96,0]\n",
    "    plt.plot(a_pred,'r-',label=\"prediction\")\n",
    "    plt.plot(a_true,'b-',label=\"true\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_oneday.jpg')\n",
    "#    plt.show()\n",
    "\n",
    "def plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path):\n",
    "    ###train_rmse & test_rmse\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_rmse, 'r-', label=\"train_rmse\")\n",
    "    plt.plot(test_rmse, 'b-', label=\"test_rmse\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/rmse.jpg')\n",
    "#    plt.show()\n",
    "    #### train_loss & train_rmse\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_loss,'b-', label='train_loss')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_loss.jpg')\n",
    "#    plt.show()\n",
    "    #plt.close\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_loss[150:],'b-', label='train_loss')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_loss[150:].jpg')\n",
    "#    plt.show()\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_rmse,'b-', label='train_rmse')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_rmse.jpg')\n",
    "#    plt.show()\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(train_rmse[150:],'b-', label='train_rmse')\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/train_rmse[150:].jpg')\n",
    "#    plt.show()\n",
    "    ##### test\n",
    "    ### accuracy\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_acc, 'b-', label=\"test_acc\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_acc.jpg')\n",
    "#    plt.show()\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_acc[150:], 'b-', label=\"test_acc\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_acc[150:].jpg')\n",
    "#    plt.show()\n",
    "    ### rmse\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_rmse, 'b-', label=\"test_rmse\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_rmse.jpg')\n",
    "#    plt.show()\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_rmse[150:], 'b-', label=\"test_rmse\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_rmse[150:].jpg')\n",
    "#    plt.show()\n",
    "    ### mae\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_mae, 'b-', label=\"test_mae\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_mae.jpg')\n",
    "#    plt.show()\n",
    "    fig1 = plt.figure(figsize=(5,3))\n",
    "    plt.plot(test_mae[150:], 'b-', label=\"test_mae\")\n",
    "    plt.legend(loc='best',fontsize=10)\n",
    "    plt.savefig(path+'/test_mae[150:].jpg')\n",
    "#    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mXl2fJk_exFp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "def preprocess_data(data, time_len, rate, seq_len, pre_len):\n",
    "    train_size = int(time_len * rate)\n",
    "    train_data = data[0:train_size]\n",
    "    test_data = data[train_size:time_len]\n",
    "\n",
    "    trainX, trainY, testX, testY = [], [], [], []\n",
    "    for i in range(len(train_data) - seq_len - pre_len):\n",
    "        a = train_data[i: i + seq_len + pre_len]\n",
    "        trainX.append(a[0 : seq_len])\n",
    "        trainY.append(a[seq_len : seq_len + pre_len])\n",
    "    for i in range(len(test_data) - seq_len -pre_len):\n",
    "        b = test_data[i: i + seq_len + pre_len]\n",
    "        testX.append(b[0 : seq_len])\n",
    "        testY.append(b[seq_len : seq_len + pre_len])\n",
    "\n",
    "    trainX1 = np.array(trainX)\n",
    "    trainY1 = np.array(trainY)\n",
    "    testX1 = np.array(testX)\n",
    "    testY1 = np.array(testY)\n",
    "    return trainX1, trainY1, testX1, testY1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YMY-EUX1ermx"
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import tensorflow as tf\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "\n",
    "def normalized_adj(adj):\n",
    "    # Convert the adjacency matrix to a TensorFlow tensor\n",
    "    adj = tf.convert_to_tensor(adj, dtype=tf.float32)\n",
    "\n",
    "    # Calculate the row sum\n",
    "    rowsum = tf.reduce_sum(adj, axis=1)\n",
    "\n",
    "    # Calculate the inverse square root of the row sums\n",
    "    d_inv_sqrt = 1.0 / tf.sqrt(tf.maximum(rowsum, 1e-12))  # Add a small constant to avoid division by zero\n",
    "\n",
    "    # Create a diagonal matrix of the inverse square root\n",
    "    d_mat_inv_sqrt = tf.linalg.diag(d_inv_sqrt)\n",
    "\n",
    "    # Calculate the normalized adjacency matrix\n",
    "    normalized_adj = tf.matmul(tf.matmul(d_mat_inv_sqrt,adj), d_mat_inv_sqrt)\n",
    "\n",
    "    return normalized_adj\n",
    "# def normalized_adj(adj):\n",
    "#     adj = sp.coo_matrix(adj)\n",
    "#     rowsum = np.array(adj.sum(1))\n",
    "#     d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
    "#     d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
    "#     d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
    "#     normalized_adj = adj.dot(d_mat_inv_sqrt).transpose().dot(d_mat_inv_sqrt).tocoo()\n",
    "#     normalized_adj = normalized_adj.astype(np.float32)\n",
    "#     return normalized_adj\n",
    "def convert_sparse_matrix_to_sparse_tensor(X):\n",
    "    coo = X.tocoo()\n",
    "    indices = np.mat([coo.row, coo.col]).transpose()\n",
    "    return tf.SparseTensor(indices, coo.data, coo.shape)\n",
    "def sparse_to_tuple(mx):\n",
    "    mx = mx.tocoo()\n",
    "    coords = np.vstack((mx.row, mx.col)).transpose()\n",
    "    L = tf.SparseTensor(coords, mx.data, mx.shape)\n",
    "    return tf.sparse.reorder(L)\n",
    "\n",
    "def calculate_laplacian(adj, lambda_max=1):\n",
    "    # print(\"adj\",adj.shape)\n",
    "    # adj = normalized_adj(adj + sp.eye(adj.shape[0]))\n",
    "    adj = normalized_adj(adj + tf.eye(adj.shape[0], dtype=tf.float32))\n",
    "    # adj = sp.csr_matrix(adj)\n",
    "    # adj = adj.astype(np.float32)\n",
    "    return adj\n",
    "\n",
    "def weight_variable_glorot(input_dim, output_dim, name=\"\"):\n",
    "    init_range = np.sqrt(6.0 / (input_dim + output_dim))\n",
    "    initial = tf.compat.v1.random_uniform([input_dim, output_dim], minval=-init_range,\n",
    "                            maxval=init_range, dtype=tf.float32)\n",
    "\n",
    "    return tf.Variable(initial,name=name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "brfXmIdqF8EI"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def pearson_correlation_coefficient(x, y):\n",
    "    # print(x.shape)\n",
    "    # Calculate the mean of x and y\n",
    "    mean_x = np.mean(x)\n",
    "    mean_y = np.mean(y)\n",
    "\n",
    "    # Calculate the covariance and variances\n",
    "    cov_xy = np.sum((x - mean_x) * (y - mean_y))\n",
    "    var_x = np.sum(np.square(x - mean_x))\n",
    "    var_y = np.sum(np.square(y - mean_y))\n",
    "\n",
    "    if var_x > 0 and var_y > 0:\n",
    "        # Calculate the Pearson correlation coefficient\n",
    "        pearson_corr = cov_xy / np.sqrt(var_x * var_y)\n",
    "    else:\n",
    "        # If variances are zero, correlation is undefined; return 0 or another appropriate value\n",
    "        pearson_corr = 0.0  # You can change this to another value if needed\n",
    "\n",
    "    return pearson_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "og8T1Gay3tsI"
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# def dynamic_adjacency(x0,adj):\n",
    "#         xy = x0.transpose(1,2,0)\n",
    "#         xl = list(xy)\n",
    "#         adjL = []\n",
    "\n",
    "#         for x in range(len(xl)):\n",
    "#           Acc = np.zeros((156, 156))\n",
    "#           for i in range(156):\n",
    "#             for j in range(156):\n",
    "#               Acc[i][j] = np.abs(pearson_correlation_coefficient(xl[x][i],xl[x][j]))\n",
    "#           Acc = 0.01 *Acc\n",
    "#           Ac = np.round_(Acc, decimals = 3)\n",
    "#           Ad = Ac+adj\n",
    "#           adjL.append(Ad)\n",
    "\n",
    "#         # ad = 0.1*adj\n",
    "#         return adjL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9yCRWXiHEugO"
   },
   "outputs": [],
   "source": [
    "def _nan_to_zero(x):\n",
    "        is_not_nan = tf.math.logical_not(tf.math.is_nan(x))\n",
    "        is_not_nan = tf.cast(is_not_nan, tf.float32)\n",
    "\n",
    "        return tf.math.multiply_no_nan(x, is_not_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3dxLzniDL7ek"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "def dynamic_adjacency(x0, adj):\n",
    "    xy = x0.transpose(2,0,1)\n",
    "    xyr = xy.reshape( xy.shape[0],-1)\n",
    "\n",
    "    x0_tensor = tf.convert_to_tensor(xyr, dtype=tf.float32)\n",
    "    adj_tensor = tf.convert_to_tensor(adj, dtype=tf.float32)\n",
    "    # print(x0)\n",
    "    # Calculate the Pearson correlation coefficients using TensorFlow operations\n",
    "    xyr = x0_tensor  # Transpose to match TensorFlow broadcasting\n",
    "    Acc = tf.abs(tfp.stats.correlation(xyr, xyr, sample_axis=1, event_axis=0))\n",
    "    Acc = _nan_to_zero(Acc)\n",
    "    Acc = 0.01 * Acc\n",
    "\n",
    "    # Add Acc and adj tensors\n",
    "    Ad = tf.add(Acc, adj_tensor)\n",
    "\n",
    "    return Ad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "jNJs5xMHe4od"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.compat.v1.nn.rnn_cell import RNNCell\n",
    "# from utils import calculate_laplacian\n",
    "\n",
    "class tgcnCell(RNNCell):\n",
    "    \"\"\"Temporal Graph Convolutional Network \"\"\"\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def __init__(self, num_units,adj, num_nodes, input_size=None,\n",
    "                 act=tf.nn.tanh, reuse=None):\n",
    "\n",
    "        super(tgcnCell, self).__init__(_reuse=reuse)\n",
    "        self._act = act\n",
    "        self._nodes = num_nodes\n",
    "        self._units = num_units\n",
    "        # self._adj = []\n",
    "        # self.count = 0\n",
    "        # print(\"adjtgcn\",adj.shape)\n",
    "        # for x in range(7):\n",
    "        self._adj = (calculate_laplacian(adj))\n",
    "\n",
    "\n",
    "    @property\n",
    "    def state_size(self):\n",
    "        return self._nodes * self._units\n",
    "\n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return self._units\n",
    "\n",
    "    def __call__(self, inputs,state, scope=None):\n",
    "\n",
    "\n",
    "        with tf.compat.v1.variable_scope(scope or \"tgcn\"):\n",
    "            with tf.compat.v1.variable_scope(\"gates\"):\n",
    "                # print(\"inputs1\",inputs.shape)\n",
    "                value = tf.nn.sigmoid(\n",
    "                    self._gc(inputs, state, 2 * self._units, bias=1.0, scope=scope))\n",
    "                # self.count = self.count+1\n",
    "                # print(\"inputs\",inputs.shape)\n",
    "                r, u = tf.split(value=value, num_or_size_splits=2, axis=1)\n",
    "\n",
    "            with tf.compat.v1.variable_scope(\"candidate\"):\n",
    "                r_state = r * state\n",
    "                c = self._act(self._gc(inputs, r_state, self._units, scope=scope))\n",
    "            new_h = u * state + (1 - u) * c\n",
    "        return new_h, new_h\n",
    "\n",
    "\n",
    "    def _gc(self, inputs, state, output_size, bias=0.0, scope=None):\n",
    "        ## inputs:(-1,num_nodes)\n",
    "\n",
    "        inputs = tf.expand_dims(inputs, 2)\n",
    "        # print(\"inputs\",inputs.shape)\n",
    "        ## state:(batch,num_node,gru_units)\n",
    "        state = tf.reshape(state, (-1, self._nodes, self._units))\n",
    "        ## concat\n",
    "        # print(\"state\",state.shape)\n",
    "        x_s = tf.concat([inputs, state], axis=2)\n",
    "        input_size = x_s.get_shape()[2]\n",
    "\n",
    "        x0 = tf.transpose(x_s, perm=[1, 2, 0])\n",
    "        x0 = tf.reshape(x0, shape=[self._nodes, -1])\n",
    "\n",
    "        scope = tf.compat.v1.get_variable_scope()\n",
    "        with tf.compat.v1.variable_scope(scope):\n",
    "            # for m in self._adj:\n",
    "            x1 = tf.matmul(self._adj, x0)\n",
    "            # print(\"xx1\",x1.shape)\n",
    "            x = tf.reshape(x1, shape=[self._nodes, input_size,-1])\n",
    "            x = tf.transpose(x,perm=[2,0,1])\n",
    "            x = tf.reshape(x, shape=[-1, input_size])\n",
    "            weights = tf.compat.v1.get_variable(\n",
    "                'weights', [input_size, output_size], initializer=tf.keras.initializers.GlorotUniform())\n",
    "            x = tf.matmul(x, weights)  # (batch_size * self._nodes, output_size)\n",
    "            biases = tf.compat.v1.get_variable(\n",
    "                \"biases\", [output_size], initializer=tf.constant_initializer(bias))\n",
    "            x = tf.nn.bias_add(x, biases)\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes, output_size])\n",
    "            x = tf.reshape(x, shape=[-1, self._nodes * output_size])\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sJysI8VNaSEz",
    "outputId": "8d0b8cbe-9f3e-4912-9f81-6213bbbd157b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data (2000, 10)\n",
      "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From C:\\Users\\Afia\\AppData\\Local\\Temp\\ipykernel_15432\\839810285.py:58: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API\n",
      "s Tensor(\"mul:0\", shape=(None, 3), dtype=float32)\n",
      "bata Tensor(\"Softmax:0\", shape=(None, 3), dtype=float32)\n",
      "context Tensor(\"transpose_1:0\", shape=(None, 10, 3), dtype=float32)\n",
      "Iter:0 train_rmse:75.56 test_loss:2.497e+03 test_rmse:1.123 test_acc:-3.487\n",
      "INFO:tensorflow:out/tgcn_att\\tgcn_att_sz_lr0.001_batch32_unit64_seq3_pre1_epoch500/model_100\\graphGRU_pre_0-0.data-00000-of-00001\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:out/tgcn_att\\tgcn_att_sz_lr0.001_batch32_unit64_seq3_pre1_epoch500/model_100\\graphGRU_pre_0-0.index\n",
      "INFO:tensorflow:200\n",
      "INFO:tensorflow:out/tgcn_att\\tgcn_att_sz_lr0.001_batch32_unit64_seq3_pre1_epoch500/model_100\\graphGRU_pre_0-0.meta\n",
      "INFO:tensorflow:1400\n",
      "Iter:1 train_rmse:57.59 test_loss:1.433e+03 test_rmse:0.8508 test_acc:-2.4\n",
      "Iter:2 train_rmse:33.58 test_loss:478.4 test_rmse:0.4914 test_acc:-0.9635\n",
      "Iter:3 train_rmse:11.23 test_loss:47.88 test_rmse:0.155 test_acc:0.3804\n",
      "Iter:4 train_rmse:6.978 test_loss:16.43 test_rmse:0.09036 test_acc:0.6389\n",
      "Iter:5 train_rmse:6.961 test_loss:16.27 test_rmse:0.08994 test_acc:0.6406\n",
      "Iter:6 train_rmse:6.925 test_loss:16.02 test_rmse:0.08929 test_acc:0.6432\n",
      "Iter:7 train_rmse:6.9 test_loss:15.83 test_rmse:0.08878 test_acc:0.6453\n",
      "Iter:8 train_rmse:6.875 test_loss:15.65 test_rmse:0.08827 test_acc:0.6473\n",
      "Iter:9 train_rmse:6.852 test_loss:15.47 test_rmse:0.08778 test_acc:0.6492\n",
      "Iter:10 train_rmse:6.831 test_loss:15.3 test_rmse:0.08731 test_acc:0.6511\n",
      "Iter:11 train_rmse:6.811 test_loss:15.14 test_rmse:0.08686 test_acc:0.6529\n",
      "Iter:12 train_rmse:6.794 test_loss:14.98 test_rmse:0.08643 test_acc:0.6546\n",
      "Iter:13 train_rmse:6.777 test_loss:14.84 test_rmse:0.08603 test_acc:0.6562\n",
      "Iter:14 train_rmse:6.763 test_loss:14.71 test_rmse:0.08565 test_acc:0.6578\n",
      "Iter:15 train_rmse:6.75 test_loss:14.58 test_rmse:0.0853 test_acc:0.6592\n",
      "Iter:16 train_rmse:6.738 test_loss:14.47 test_rmse:0.08497 test_acc:0.6605\n",
      "Iter:17 train_rmse:6.728 test_loss:14.36 test_rmse:0.08467 test_acc:0.6617\n",
      "Iter:18 train_rmse:6.718 test_loss:14.27 test_rmse:0.0844 test_acc:0.6628\n",
      "Iter:19 train_rmse:6.71 test_loss:14.18 test_rmse:0.08415 test_acc:0.6638\n",
      "Iter:20 train_rmse:6.702 test_loss:14.1 test_rmse:0.08392 test_acc:0.6647\n",
      "Iter:21 train_rmse:6.695 test_loss:14.03 test_rmse:0.08372 test_acc:0.6655\n",
      "Iter:22 train_rmse:6.689 test_loss:13.97 test_rmse:0.08354 test_acc:0.6662\n",
      "Iter:23 train_rmse:6.684 test_loss:13.91 test_rmse:0.08338 test_acc:0.6668\n",
      "Iter:24 train_rmse:6.679 test_loss:13.86 test_rmse:0.08323 test_acc:0.6674\n",
      "Iter:25 train_rmse:6.674 test_loss:13.82 test_rmse:0.0831 test_acc:0.6679\n",
      "Iter:26 train_rmse:6.67 test_loss:13.77 test_rmse:0.08298 test_acc:0.6684\n",
      "Iter:27 train_rmse:6.666 test_loss:13.74 test_rmse:0.08287 test_acc:0.6688\n",
      "Iter:28 train_rmse:6.662 test_loss:13.7 test_rmse:0.08278 test_acc:0.6692\n",
      "Iter:29 train_rmse:6.658 test_loss:13.67 test_rmse:0.08269 test_acc:0.6696\n",
      "Iter:30 train_rmse:6.654 test_loss:13.64 test_rmse:0.0826 test_acc:0.6699\n",
      "Iter:31 train_rmse:6.65 test_loss:13.61 test_rmse:0.08253 test_acc:0.6702\n",
      "Iter:32 train_rmse:6.646 test_loss:13.59 test_rmse:0.08245 test_acc:0.6705\n",
      "Iter:33 train_rmse:6.642 test_loss:13.56 test_rmse:0.08238 test_acc:0.6708\n",
      "Iter:34 train_rmse:6.638 test_loss:13.54 test_rmse:0.08231 test_acc:0.6711\n",
      "Iter:35 train_rmse:6.633 test_loss:13.51 test_rmse:0.08225 test_acc:0.6714\n",
      "Iter:36 train_rmse:6.629 test_loss:13.49 test_rmse:0.08218 test_acc:0.6716\n",
      "Iter:37 train_rmse:6.624 test_loss:13.46 test_rmse:0.0821 test_acc:0.6719\n",
      "Iter:38 train_rmse:6.618 test_loss:13.44 test_rmse:0.08203 test_acc:0.6722\n",
      "Iter:39 train_rmse:6.612 test_loss:13.41 test_rmse:0.08194 test_acc:0.6726\n",
      "Iter:40 train_rmse:6.605 test_loss:13.38 test_rmse:0.08185 test_acc:0.6729\n",
      "Iter:41 train_rmse:6.598 test_loss:13.34 test_rmse:0.08175 test_acc:0.6733\n",
      "Iter:42 train_rmse:6.59 test_loss:13.3 test_rmse:0.08164 test_acc:0.6738\n",
      "Iter:43 train_rmse:6.581 test_loss:13.26 test_rmse:0.08151 test_acc:0.6743\n",
      "Iter:44 train_rmse:6.571 test_loss:13.21 test_rmse:0.08137 test_acc:0.6749\n",
      "Iter:45 train_rmse:6.56 test_loss:13.16 test_rmse:0.08122 test_acc:0.6755\n",
      "Iter:46 train_rmse:6.548 test_loss:13.11 test_rmse:0.08105 test_acc:0.6761\n",
      "Iter:47 train_rmse:6.535 test_loss:13.05 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:48 train_rmse:6.522 test_loss:12.99 test_rmse:0.08071 test_acc:0.6775\n",
      "Iter:49 train_rmse:6.508 test_loss:12.94 test_rmse:0.08053 test_acc:0.6782\n",
      "Iter:50 train_rmse:6.495 test_loss:12.89 test_rmse:0.08037 test_acc:0.6788\n",
      "Iter:51 train_rmse:6.481 test_loss:12.84 test_rmse:0.08022 test_acc:0.6794\n",
      "Iter:52 train_rmse:6.468 test_loss:12.79 test_rmse:0.08008 test_acc:0.68\n",
      "Iter:53 train_rmse:6.455 test_loss:12.75 test_rmse:0.07996 test_acc:0.6805\n",
      "Iter:54 train_rmse:6.443 test_loss:12.72 test_rmse:0.07986 test_acc:0.6809\n",
      "Iter:55 train_rmse:6.432 test_loss:12.69 test_rmse:0.07977 test_acc:0.6812\n",
      "Iter:56 train_rmse:6.421 test_loss:12.66 test_rmse:0.0797 test_acc:0.6815\n",
      "Iter:57 train_rmse:6.412 test_loss:12.64 test_rmse:0.07964 test_acc:0.6818\n",
      "Iter:58 train_rmse:6.403 test_loss:12.63 test_rmse:0.07959 test_acc:0.682\n",
      "Iter:59 train_rmse:6.395 test_loss:12.62 test_rmse:0.07955 test_acc:0.6821\n",
      "Iter:60 train_rmse:6.387 test_loss:12.61 test_rmse:0.07953 test_acc:0.6822\n",
      "Iter:61 train_rmse:6.381 test_loss:12.6 test_rmse:0.07951 test_acc:0.6823\n",
      "Iter:62 train_rmse:6.375 test_loss:12.6 test_rmse:0.07951 test_acc:0.6823\n",
      "Iter:63 train_rmse:6.37 test_loss:12.6 test_rmse:0.07951 test_acc:0.6823\n",
      "Iter:64 train_rmse:6.366 test_loss:12.6 test_rmse:0.07952 test_acc:0.6823\n",
      "Iter:65 train_rmse:6.362 test_loss:12.6 test_rmse:0.07953 test_acc:0.6822\n",
      "Iter:66 train_rmse:6.359 test_loss:12.61 test_rmse:0.07955 test_acc:0.6821\n",
      "Iter:67 train_rmse:6.356 test_loss:12.62 test_rmse:0.07958 test_acc:0.682\n",
      "Iter:68 train_rmse:6.354 test_loss:12.63 test_rmse:0.07961 test_acc:0.6819\n",
      "Iter:69 train_rmse:6.353 test_loss:12.64 test_rmse:0.07965 test_acc:0.6817\n",
      "Iter:70 train_rmse:6.352 test_loss:12.65 test_rmse:0.07969 test_acc:0.6816\n",
      "Iter:71 train_rmse:6.351 test_loss:12.66 test_rmse:0.07973 test_acc:0.6814\n",
      "Iter:72 train_rmse:6.351 test_loss:12.67 test_rmse:0.07977 test_acc:0.6812\n",
      "Iter:73 train_rmse:6.351 test_loss:12.69 test_rmse:0.07982 test_acc:0.6811\n",
      "Iter:74 train_rmse:6.351 test_loss:12.7 test_rmse:0.07986 test_acc:0.6809\n",
      "Iter:75 train_rmse:6.352 test_loss:12.71 test_rmse:0.07991 test_acc:0.6807\n",
      "Iter:76 train_rmse:6.352 test_loss:12.73 test_rmse:0.07995 test_acc:0.6805\n",
      "Iter:77 train_rmse:6.353 test_loss:12.74 test_rmse:0.08 test_acc:0.6803\n",
      "Iter:78 train_rmse:6.354 test_loss:12.75 test_rmse:0.08004 test_acc:0.6801\n",
      "Iter:79 train_rmse:6.355 test_loss:12.77 test_rmse:0.08009 test_acc:0.68\n",
      "Iter:80 train_rmse:6.356 test_loss:12.78 test_rmse:0.08013 test_acc:0.6798\n",
      "Iter:81 train_rmse:6.357 test_loss:12.79 test_rmse:0.08017 test_acc:0.6796\n",
      "Iter:82 train_rmse:6.358 test_loss:12.81 test_rmse:0.08022 test_acc:0.6795\n",
      "Iter:83 train_rmse:6.359 test_loss:12.82 test_rmse:0.08025 test_acc:0.6793\n",
      "Iter:84 train_rmse:6.361 test_loss:12.83 test_rmse:0.08029 test_acc:0.6792\n",
      "Iter:85 train_rmse:6.362 test_loss:12.84 test_rmse:0.08033 test_acc:0.679\n",
      "Iter:86 train_rmse:6.363 test_loss:12.85 test_rmse:0.08036 test_acc:0.6789\n",
      "Iter:87 train_rmse:6.364 test_loss:12.86 test_rmse:0.08039 test_acc:0.6788\n",
      "Iter:88 train_rmse:6.365 test_loss:12.87 test_rmse:0.08042 test_acc:0.6786\n",
      "Iter:89 train_rmse:6.366 test_loss:12.88 test_rmse:0.08045 test_acc:0.6785\n",
      "Iter:90 train_rmse:6.367 test_loss:12.89 test_rmse:0.08048 test_acc:0.6784\n",
      "Iter:91 train_rmse:6.368 test_loss:12.89 test_rmse:0.08051 test_acc:0.6783\n",
      "Iter:92 train_rmse:6.369 test_loss:12.9 test_rmse:0.08053 test_acc:0.6782\n",
      "Iter:93 train_rmse:6.37 test_loss:12.91 test_rmse:0.08055 test_acc:0.6781\n",
      "Iter:94 train_rmse:6.37 test_loss:12.91 test_rmse:0.08058 test_acc:0.678\n",
      "Iter:95 train_rmse:6.371 test_loss:12.92 test_rmse:0.08059 test_acc:0.678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:96 train_rmse:6.372 test_loss:12.93 test_rmse:0.08061 test_acc:0.6779\n",
      "Iter:97 train_rmse:6.372 test_loss:12.93 test_rmse:0.08063 test_acc:0.6778\n",
      "Iter:98 train_rmse:6.373 test_loss:12.94 test_rmse:0.08065 test_acc:0.6777\n",
      "Iter:99 train_rmse:6.374 test_loss:12.94 test_rmse:0.08066 test_acc:0.6777\n",
      "Iter:100 train_rmse:6.374 test_loss:12.94 test_rmse:0.08068 test_acc:0.6776\n",
      "Iter:101 train_rmse:6.375 test_loss:12.95 test_rmse:0.08069 test_acc:0.6776\n",
      "Iter:102 train_rmse:6.375 test_loss:12.95 test_rmse:0.0807 test_acc:0.6775\n",
      "Iter:103 train_rmse:6.376 test_loss:12.95 test_rmse:0.08071 test_acc:0.6775\n",
      "Iter:104 train_rmse:6.376 test_loss:12.96 test_rmse:0.08072 test_acc:0.6774\n",
      "Iter:105 train_rmse:6.376 test_loss:12.96 test_rmse:0.08073 test_acc:0.6774\n",
      "Iter:106 train_rmse:6.377 test_loss:12.96 test_rmse:0.08074 test_acc:0.6774\n",
      "Iter:107 train_rmse:6.377 test_loss:12.97 test_rmse:0.08075 test_acc:0.6773\n",
      "Iter:108 train_rmse:6.377 test_loss:12.97 test_rmse:0.08076 test_acc:0.6773\n",
      "Iter:109 train_rmse:6.378 test_loss:12.97 test_rmse:0.08077 test_acc:0.6773\n",
      "Iter:110 train_rmse:6.378 test_loss:12.97 test_rmse:0.08077 test_acc:0.6772\n",
      "Iter:111 train_rmse:6.378 test_loss:12.97 test_rmse:0.08078 test_acc:0.6772\n",
      "Iter:112 train_rmse:6.379 test_loss:12.98 test_rmse:0.08079 test_acc:0.6772\n",
      "Iter:113 train_rmse:6.379 test_loss:12.98 test_rmse:0.08079 test_acc:0.6772\n",
      "Iter:114 train_rmse:6.379 test_loss:12.98 test_rmse:0.0808 test_acc:0.6771\n",
      "Iter:115 train_rmse:6.379 test_loss:12.98 test_rmse:0.0808 test_acc:0.6771\n",
      "Iter:116 train_rmse:6.38 test_loss:12.98 test_rmse:0.08081 test_acc:0.6771\n",
      "Iter:117 train_rmse:6.38 test_loss:12.98 test_rmse:0.08081 test_acc:0.6771\n",
      "Iter:118 train_rmse:6.38 test_loss:12.98 test_rmse:0.08081 test_acc:0.6771\n",
      "Iter:119 train_rmse:6.38 test_loss:12.98 test_rmse:0.08082 test_acc:0.6771\n",
      "Iter:120 train_rmse:6.38 test_loss:12.99 test_rmse:0.08082 test_acc:0.677\n",
      "Iter:121 train_rmse:6.38 test_loss:12.99 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:122 train_rmse:6.381 test_loss:12.99 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:123 train_rmse:6.381 test_loss:12.99 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:124 train_rmse:6.381 test_loss:12.99 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:125 train_rmse:6.381 test_loss:12.99 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:126 train_rmse:6.381 test_loss:12.99 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:127 train_rmse:6.381 test_loss:12.99 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:128 train_rmse:6.381 test_loss:12.99 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:129 train_rmse:6.382 test_loss:12.99 test_rmse:0.08085 test_acc:0.677\n",
      "Iter:130 train_rmse:6.382 test_loss:12.99 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:131 train_rmse:6.382 test_loss:12.99 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:132 train_rmse:6.382 test_loss:12.99 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:133 train_rmse:6.382 test_loss:12.99 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:134 train_rmse:6.382 test_loss:12.99 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:135 train_rmse:6.382 test_loss:12.99 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:136 train_rmse:6.382 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:137 train_rmse:6.382 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:138 train_rmse:6.382 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:139 train_rmse:6.383 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:140 train_rmse:6.383 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:141 train_rmse:6.383 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:142 train_rmse:6.383 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:143 train_rmse:6.383 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:144 train_rmse:6.383 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:145 train_rmse:6.383 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:146 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:147 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:148 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:149 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:150 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:151 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:152 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:153 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:154 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:155 train_rmse:6.383 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:156 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:157 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:158 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:159 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:160 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:161 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:162 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:163 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:164 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:165 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:166 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:167 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:168 train_rmse:6.384 test_loss:13.0 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:169 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:170 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:171 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:172 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:173 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:174 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:175 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:176 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:177 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:178 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:179 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:180 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:181 train_rmse:6.385 test_loss:13.0 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:182 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:183 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:184 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:185 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:186 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:187 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:188 train_rmse:6.385 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:189 train_rmse:6.385 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:190 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:191 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:192 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:193 train_rmse:6.384 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:194 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:195 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:196 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:197 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:198 train_rmse:6.385 test_loss:12.99 test_rmse:0.08088 test_acc:0.6768\n",
      "Iter:199 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:200 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:201 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:202 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:203 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:204 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:205 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:206 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:207 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:208 train_rmse:6.385 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:209 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:210 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:211 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:212 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:213 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:214 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:215 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6768\n",
      "Iter:216 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:217 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:218 train_rmse:6.384 test_loss:12.99 test_rmse:0.08087 test_acc:0.6769\n",
      "Iter:219 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:220 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:221 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:222 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:223 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:224 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:225 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:226 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:227 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:228 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:229 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:230 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:231 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:232 train_rmse:6.384 test_loss:12.99 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:233 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:234 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:235 train_rmse:6.384 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:236 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:237 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:238 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:239 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:240 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:241 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:242 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:243 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:244 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:245 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:246 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:247 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:248 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:249 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:250 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:251 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:252 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:253 train_rmse:6.384 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:254 train_rmse:6.384 test_loss:12.98 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:255 train_rmse:6.384 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:256 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:257 train_rmse:6.384 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:258 train_rmse:6.384 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:259 train_rmse:6.384 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:260 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:261 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:262 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:263 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:264 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:265 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:266 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:267 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:268 train_rmse:6.383 test_loss:12.98 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:269 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:270 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:271 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:272 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:273 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:274 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:275 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:276 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:277 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:278 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:279 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:280 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:281 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:282 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:283 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:284 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:285 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:286 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:287 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:288 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:289 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:290 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:291 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:292 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:293 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:294 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:295 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:296 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:297 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:298 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:299 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:300 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:301 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:302 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:303 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:304 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:305 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:306 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:307 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:308 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:309 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:310 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:311 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:312 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:313 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:314 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:315 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:316 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:317 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:318 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:319 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:320 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:321 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:322 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:323 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:324 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:325 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:326 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:327 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:328 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:329 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:330 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:331 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:332 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:333 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:334 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:335 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:336 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:337 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:338 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:339 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:340 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:341 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:342 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:343 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:344 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:345 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:346 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:347 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:348 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:349 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:350 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:351 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:352 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:353 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:354 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:355 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:356 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:357 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:358 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:359 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:360 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:361 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:362 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:363 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:364 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:365 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:366 train_rmse:6.383 test_loss:12.97 test_rmse:0.08082 test_acc:0.677\n",
      "Iter:367 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:368 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:369 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:370 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:371 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:372 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:373 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:374 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:375 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:376 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:377 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:378 train_rmse:6.382 test_loss:12.96 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:379 train_rmse:6.382 test_loss:12.96 test_rmse:0.08082 test_acc:0.677\n",
      "Iter:380 train_rmse:6.378 test_loss:12.95 test_rmse:0.08076 test_acc:0.6773\n",
      "Iter:381 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:382 train_rmse:6.383 test_loss:12.98 test_rmse:0.08086 test_acc:0.6769\n",
      "Iter:383 train_rmse:6.383 test_loss:12.97 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:384 train_rmse:6.383 test_loss:12.97 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:385 train_rmse:6.383 test_loss:12.97 test_rmse:0.08085 test_acc:0.6769\n",
      "Iter:386 train_rmse:6.383 test_loss:12.97 test_rmse:0.08085 test_acc:0.677\n",
      "Iter:387 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:388 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:389 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:390 train_rmse:6.383 test_loss:12.97 test_rmse:0.08084 test_acc:0.677\n",
      "Iter:391 train_rmse:6.383 test_loss:12.97 test_rmse:0.08083 test_acc:0.677\n",
      "Iter:392 train_rmse:6.383 test_loss:12.96 test_rmse:0.08082 test_acc:0.677\n",
      "Iter:393 train_rmse:6.382 test_loss:12.96 test_rmse:0.08081 test_acc:0.6771\n",
      "Iter:394 train_rmse:6.372 test_loss:12.91 test_rmse:0.08066 test_acc:0.6777\n",
      "Iter:395 train_rmse:6.377 test_loss:12.94 test_rmse:0.08075 test_acc:0.6773\n",
      "Iter:396 train_rmse:6.38 test_loss:12.95 test_rmse:0.08078 test_acc:0.6772\n",
      "Iter:397 train_rmse:6.382 test_loss:12.96 test_rmse:0.08081 test_acc:0.6771\n",
      "Iter:398 train_rmse:6.382 test_loss:12.96 test_rmse:0.08081 test_acc:0.6771\n",
      "Iter:399 train_rmse:6.382 test_loss:12.96 test_rmse:0.08081 test_acc:0.6771\n",
      "Iter:400 train_rmse:6.381 test_loss:12.95 test_rmse:0.08077 test_acc:0.6772\n",
      "Iter:401 train_rmse:6.35 test_loss:12.81 test_rmse:0.08036 test_acc:0.6789\n",
      "Iter:402 train_rmse:6.378 test_loss:12.93 test_rmse:0.08072 test_acc:0.6775\n",
      "Iter:403 train_rmse:6.29 test_loss:12.49 test_rmse:0.07931 test_acc:0.6831\n",
      "Iter:404 train_rmse:6.023 test_loss:11.43 test_rmse:0.07585 test_acc:0.6969\n",
      "Iter:405 train_rmse:5.914 test_loss:10.9 test_rmse:0.07403 test_acc:0.7042\n",
      "Iter:406 train_rmse:5.977 test_loss:11.04 test_rmse:0.07452 test_acc:0.7022\n",
      "Iter:407 train_rmse:5.977 test_loss:10.96 test_rmse:0.07425 test_acc:0.7033\n",
      "Iter:408 train_rmse:5.98 test_loss:10.94 test_rmse:0.07417 test_acc:0.7036\n",
      "Iter:409 train_rmse:5.98 test_loss:10.91 test_rmse:0.07406 test_acc:0.7041\n",
      "Iter:410 train_rmse:5.982 test_loss:10.9 test_rmse:0.07402 test_acc:0.7042\n",
      "Iter:411 train_rmse:5.982 test_loss:10.88 test_rmse:0.07398 test_acc:0.7044\n",
      "Iter:412 train_rmse:5.983 test_loss:10.88 test_rmse:0.07396 test_acc:0.7045\n",
      "Iter:413 train_rmse:5.984 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:414 train_rmse:5.984 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:415 train_rmse:5.985 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:416 train_rmse:5.985 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:417 train_rmse:5.985 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:418 train_rmse:5.986 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:419 train_rmse:5.986 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:420 train_rmse:5.986 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:421 train_rmse:5.986 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:422 train_rmse:5.986 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter:423 train_rmse:5.986 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:424 train_rmse:5.986 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:425 train_rmse:5.986 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:426 train_rmse:5.986 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:427 train_rmse:5.986 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:428 train_rmse:5.986 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:429 train_rmse:5.987 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:430 train_rmse:5.987 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:431 train_rmse:5.987 test_loss:10.87 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:432 train_rmse:5.988 test_loss:10.88 test_rmse:0.07395 test_acc:0.7045\n",
      "Iter:433 train_rmse:5.988 test_loss:10.88 test_rmse:0.07396 test_acc:0.7045\n",
      "Iter:434 train_rmse:5.989 test_loss:10.88 test_rmse:0.07397 test_acc:0.7044\n",
      "Iter:435 train_rmse:5.99 test_loss:10.88 test_rmse:0.07398 test_acc:0.7044\n",
      "Iter:436 train_rmse:5.991 test_loss:10.89 test_rmse:0.07399 test_acc:0.7043\n",
      "Iter:437 train_rmse:5.992 test_loss:10.89 test_rmse:0.07401 test_acc:0.7042\n",
      "Iter:438 train_rmse:5.993 test_loss:10.9 test_rmse:0.07404 test_acc:0.7041\n",
      "Iter:439 train_rmse:5.994 test_loss:10.91 test_rmse:0.07407 test_acc:0.704\n",
      "Iter:440 train_rmse:5.995 test_loss:10.92 test_rmse:0.0741 test_acc:0.7039\n",
      "Iter:441 train_rmse:5.994 test_loss:10.93 test_rmse:0.07414 test_acc:0.7037\n",
      "Iter:442 train_rmse:5.993 test_loss:10.94 test_rmse:0.07418 test_acc:0.7036\n",
      "Iter:443 train_rmse:5.99 test_loss:10.95 test_rmse:0.07422 test_acc:0.7034\n",
      "Iter:444 train_rmse:5.982 test_loss:10.96 test_rmse:0.07423 test_acc:0.7034\n",
      "Iter:445 train_rmse:5.969 test_loss:10.94 test_rmse:0.07419 test_acc:0.7036\n",
      "Iter:446 train_rmse:5.947 test_loss:10.9 test_rmse:0.07404 test_acc:0.7041\n",
      "Iter:447 train_rmse:5.911 test_loss:10.84 test_rmse:0.07382 test_acc:0.705\n",
      "Iter:448 train_rmse:5.861 test_loss:10.88 test_rmse:0.07398 test_acc:0.7044\n",
      "Iter:449 train_rmse:5.872 test_loss:10.9 test_rmse:0.07406 test_acc:0.7041\n",
      "Iter:450 train_rmse:5.844 test_loss:10.84 test_rmse:0.07383 test_acc:0.705\n",
      "Iter:451 train_rmse:5.806 test_loss:10.71 test_rmse:0.07339 test_acc:0.7068\n",
      "Iter:452 train_rmse:5.787 test_loss:10.62 test_rmse:0.07307 test_acc:0.708\n",
      "Iter:453 train_rmse:5.767 test_loss:10.53 test_rmse:0.07277 test_acc:0.7092\n",
      "Iter:454 train_rmse:5.751 test_loss:10.46 test_rmse:0.07255 test_acc:0.7101\n",
      "Iter:455 train_rmse:5.741 test_loss:10.42 test_rmse:0.07239 test_acc:0.7108\n",
      "Iter:456 train_rmse:5.731 test_loss:10.38 test_rmse:0.07225 test_acc:0.7113\n",
      "Iter:457 train_rmse:5.723 test_loss:10.35 test_rmse:0.07215 test_acc:0.7117\n",
      "Iter:458 train_rmse:5.716 test_loss:10.33 test_rmse:0.07208 test_acc:0.712\n",
      "Iter:459 train_rmse:5.711 test_loss:10.31 test_rmse:0.07202 test_acc:0.7122\n",
      "Iter:460 train_rmse:5.707 test_loss:10.31 test_rmse:0.07199 test_acc:0.7123\n",
      "Iter:461 train_rmse:5.705 test_loss:10.31 test_rmse:0.07199 test_acc:0.7123\n",
      "Iter:462 train_rmse:5.704 test_loss:10.31 test_rmse:0.07202 test_acc:0.7122\n"
     ]
    }
   ],
   "source": [
    "import pickle as pkl\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import numpy.linalg as la\n",
    "\n",
    "# from input_data import preprocess_data,load_sz_data,load_los_data\n",
    "# from tgcn import tgcnCell\n",
    "# from gru import GRUCell\n",
    "tf.compat.v1.reset_default_graph()\n",
    "# from visualization import plot_result,plot_error\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import time\n",
    "import scipy.stats as measures\n",
    "time_start = time.time()\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "train_rate =  0.8\n",
    "seq_len = 3\n",
    "output_dim = pre_len =1\n",
    "lr = 0.001\n",
    "training_epoch = 500\n",
    "batch_size = 32\n",
    "# training_epoch = 1\n",
    "gru_units = 64\n",
    "\n",
    "###### load data ######\n",
    "# if data_name == 'sz':\n",
    "#     data, adj = load_sz_data('sz')\n",
    "# if data_name == 'los':\n",
    "#     data, adj = load_los_data('los')\n",
    "los_adj = pd.read_csv('C:/Users/Afia/Downloads/sz_adj.csv',header=None)\n",
    "adj = np.mat(los_adj)\n",
    "adj = adj[:10,:10]\n",
    "data = pd.read_csv('C:/Users/Afia/Downloads/sz_speed.csv')\n",
    "data1 =np.mat(data,dtype=np.float32)\n",
    "data1 = data1[:2000,:10]\n",
    "print(\"data\",data1.shape)\n",
    "time_len = data1.shape[0]\n",
    "num_nodes = data1.shape[1]\n",
    "\n",
    "#### normalization\n",
    "max_value = np.max(data1)\n",
    "data1  = data1/max_value\n",
    "trainX, trainY, testX, testY = preprocess_data(data1, time_len, train_rate, seq_len, pre_len)\n",
    "\n",
    "totalbatch = int(trainX.shape[0]/batch_size)\n",
    "training_data_count = len(trainX)\n",
    "\n",
    "def TGCN(_X, Adj_m,weights, biases):\n",
    "    cell_1 = tgcnCell(gru_units,Adj_m, num_nodes=num_nodes)\n",
    "    cell = tf.compat.v1.nn.rnn_cell.MultiRNNCell([cell_1], state_is_tuple=True)\n",
    "    _X = tf.unstack(_X, axis=1)\n",
    "    # Adj_m = tf.unstack(Adj_m, axis=1)\n",
    "    outputs, states = tf.compat.v1.nn.static_rnn(cell, _X, dtype=tf.float32)\n",
    "    out = tf.concat(outputs, axis=0)\n",
    "    out = tf.reshape(out, shape=[seq_len,-1,num_nodes,gru_units])\n",
    "    out = tf.transpose(out, perm=[1,0,2,3])\n",
    "\n",
    "    last_output,alpha = self_attention1(out, weight_att, bias_att)\n",
    "\n",
    "    output = tf.reshape(last_output,shape=[-1,seq_len])\n",
    "    output = tf.matmul(output, weights['out']) + biases['out']\n",
    "    output = tf.reshape(output,shape=[-1,num_nodes,pre_len])\n",
    "    output = tf.transpose(output, perm=[0,2,1])\n",
    "    output = tf.reshape(output, shape=[-1,num_nodes])\n",
    "\n",
    "    return output, outputs, states, alpha\n",
    "\n",
    "def self_attention1(x, weight_att,bias_att):\n",
    "    x = tf.matmul(tf.reshape(x,[-1,gru_units]),weight_att['w1']) + bias_att['b1']\n",
    "    f = tf.matmul(tf.reshape(x, [-1, num_nodes]), weight_att['w2']) + bias_att['b2']\n",
    "    g = tf.matmul(tf.reshape(x, [-1, num_nodes]), weight_att['w2']) + bias_att['b2']\n",
    "    h = tf.matmul(tf.reshape(x, [-1, num_nodes]), weight_att['w2']) + bias_att['b2']\n",
    "\n",
    "    f1 = tf.reshape(f, [-1,seq_len])\n",
    "    g1 = tf.reshape(g, [-1,seq_len])\n",
    "    h1 = tf.reshape(h, [-1,seq_len])\n",
    "    s = g1 * f1\n",
    "    print('s',s)\n",
    "\n",
    "    beta = tf.nn.softmax(s, axis=-1)  # attention map\n",
    "    print('bata',beta)\n",
    "    context = tf.expand_dims(beta,2) * tf.reshape(x,[-1,seq_len,num_nodes])\n",
    "\n",
    "    context = tf.transpose(context,perm=[0,2,1])\n",
    "    print('context', context)\n",
    "    return context, beta\n",
    "def self_attention(x, ch, weight_att, bias_att):\n",
    "    f = tf.matmul(tf.reshape(x, [-1, gru_units]), weight_att['w'])\n",
    "    g = tf.matmul(tf.reshape(x, [-1, gru_units]), weight_att['w']) + bias_att['b_att']\n",
    "    h = tf.matmul(tf.reshape(x, [-1, gru_units]), weight_att['w']) + bias_att['b_att']\n",
    "    print('h',h)\n",
    "\n",
    "    f = tf.reshape(f, [-1,num_nodes])\n",
    "    g = tf.reshape(g, [-1,num_nodes])\n",
    "    h = tf.reshape(h, [-1,num_nodes])\n",
    "    s = g * f\n",
    "    print('s',s)\n",
    "\n",
    "    beta = tf.nn.softmax(s, axis=-1)  # attention map\n",
    "    print('bata',beta)\n",
    "    o = beta * h\n",
    "    print('o',o)\n",
    "    gamma = tf.compat.v1.get_variable(\"gamma\", [1], initializer=tf.constant_initializer(0))\n",
    "\n",
    "    o = tf.expand_dims(o, 2)\n",
    "    x = gamma * o + x\n",
    "    print('x',x)\n",
    "#   x = tf.reduce_sum(x, 2)\n",
    "    return x, beta\n",
    "###### placeholders ######\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "inputs = tf.compat.v1.placeholder(tf.float32, shape=[None, seq_len, num_nodes])\n",
    "labels = tf.compat.v1.placeholder(tf.float32, shape=[None, pre_len, num_nodes])\n",
    "# Adj_m = tf.compat.v1.placeholder(tf.float32, shape=[7,num_nodes, num_nodes])\n",
    "Adj_m = tf.compat.v1.placeholder(tf.float32, shape=[num_nodes, num_nodes])\n",
    "# weights\n",
    "weights = {\n",
    "    'out': tf.Variable(tf.compat.v1.random_normal([seq_len, pre_len], mean=1.0), name='weight_o')}\n",
    "bias = {\n",
    "    'out': tf.Variable(tf.compat.v1.random_normal([pre_len]),name='bias_o')}\n",
    "weight_att={\n",
    "    'w1':tf.Variable(tf.compat.v1.random_normal([gru_units,1], stddev=0.1),name='att_w1'),\n",
    "    'w2':tf.Variable(tf.compat.v1.random_normal([num_nodes,1], stddev=0.1),name='att_w2')}\n",
    "bias_att = {\n",
    "    'b1': tf.Variable(tf.compat.v1.random_normal([1]),name='att_b1'),\n",
    "    'b2': tf.Variable(tf.compat.v1.random_normal([1]),name='att_b2')}\n",
    "\n",
    "# if model_name == 'TGCN_att':\n",
    "pred,ttto,ttts,alpha = TGCN(inputs,Adj_m, weights, bias)\n",
    "y_pred = pred\n",
    "\n",
    "\n",
    "###### optimizer ######\n",
    "lambda_loss = 0.0015\n",
    "Lreg = lambda_loss * sum(tf.nn.l2_loss(tf_var) for tf_var in tf.compat.v1.trainable_variables())\n",
    "label = tf.reshape(labels, [-1,num_nodes])\n",
    "##loss\n",
    "loss = tf.reduce_mean(tf.nn.l2_loss(y_pred-label) + Lreg)\n",
    "##rmse\n",
    "error = tf.sqrt(tf.reduce_mean(tf.square(y_pred-label)))\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(lr).minimize(loss)\n",
    "\n",
    "###### Initialize session ######\n",
    "variables = tf.compat.v1.global_variables()\n",
    "saver = tf.compat.v1.train.Saver(tf.compat.v1.global_variables())\n",
    "#sess = tf.Session()\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "sess = tf.compat.v1.Session(config=tf.compat.v1.ConfigProto(gpu_options=gpu_options))\n",
    "tf.debugging.set_log_device_placement(True)\n",
    "sess.run(tf.compat.v1.global_variables_initializer())\n",
    "\n",
    "#out = 'out/%s'%(model_name)\n",
    "out = 'out/%s'%('tgcn_att')\n",
    "path1 = '%s_%s_lr%r_batch%r_unit%r_seq%r_pre%r_epoch%r'%('tgcn_att','sz',lr,batch_size,gru_units,seq_len,pre_len,training_epoch)\n",
    "path = os.path.join(out,path1)\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "###### evaluation ######\n",
    "def evaluation(a,b):\n",
    "    rmse = math.sqrt(mean_squared_error(a,b))\n",
    "    mae = mean_absolute_error(a, b)\n",
    "    F_norm = la.norm(a-b,'fro')/la.norm(a,'fro')\n",
    "    r2 = 1-((a-b)**2).sum()/((a-a.mean())**2).sum()\n",
    "    var = 1-(np.var(a-b))/np.var(a)\n",
    "    return rmse, mae, 1-F_norm, r2, var\n",
    "\n",
    "def extract_batch_size(_train, step, batch_size):\n",
    "    # Function to fetch a \"batch_size\" amount of data from \"(X|y)_train\" data.\n",
    "    shape = list(_train.shape)\n",
    "    shape[0] = batch_size\n",
    "    batch_s = np.empty(shape)\n",
    "    for i in range(batch_size):\n",
    "        # Loop index\n",
    "        index = ((step-1)*batch_size + i) % len(_train)\n",
    "        batch_s[i] = _train[index]\n",
    "    return batch_s\n",
    "\n",
    "\n",
    "x_axe,batch_loss,batch_rmse,batch_pred = [], [], [], []\n",
    "test_loss,test_rmse,test_mae,test_acc,test_r2,test_var,test_pred = [],[],[],[],[],[],[]\n",
    "Ad_adjt = dynamic_adjacency(testX,adj)\n",
    "add_adjt = sess.run(Ad_adjt)\n",
    "dd_adjt = np.array(add_adjt)\n",
    "for epoch in range(training_epoch):\n",
    "    for m in range(totalbatch):\n",
    "        mini_batch = trainX[m * batch_size : (m+1) * batch_size]\n",
    "        mini_label = trainY[m * batch_size : (m+1) * batch_size]\n",
    "        Ad_adj = dynamic_adjacency(mini_batch,adj)\n",
    "\n",
    "        add_adj = sess.run(Ad_adj)\n",
    "        add_adj = np.array(add_adj)\n",
    "        # print(\"Ad Adj...\",add_adj.shape,add_adj)\n",
    "        _, loss1, rmse1, train_output, alpha1 = sess.run([optimizer, loss, error, y_pred, alpha],\n",
    "                                                 feed_dict = {inputs:mini_batch,Adj_m:add_adj ,labels:mini_label})\n",
    "        batch_loss.append(loss1)\n",
    "        batch_rmse.append(rmse1 * max_value)\n",
    "\n",
    "     # Test completely at every epoch\n",
    " \n",
    "    loss2, rmse2, test_output = sess.run([loss, error, y_pred],feed_dict = {inputs:testX, Adj_m:add_adjt ,labels:testY})\n",
    "    test_label = np.reshape(testY,[-1,num_nodes])\n",
    "    rmse, mae, acc, r2_score, var_score = evaluation(test_label, test_output)\n",
    "    test_label1 = test_label * max_value\n",
    "    test_output1 = test_output * max_value\n",
    "    test_loss.append(loss2)\n",
    "    test_rmse.append(rmse * max_value)\n",
    "    test_mae.append(mae * max_value)\n",
    "\n",
    "    test_acc.append(acc)\n",
    "    test_r2.append(r2_score)\n",
    "    test_var.append(var_score)\n",
    "    test_pred.append(test_output1)\n",
    "\n",
    "    print('Iter:{}'.format(epoch),\n",
    "          'train_rmse:{:.4}'.format(batch_rmse[-1]),\n",
    "          'test_loss:{:.4}'.format(loss2),\n",
    "          'test_rmse:{:.4}'.format(rmse),\n",
    "          'test_acc:{:.4}'.format(acc))\n",
    "\n",
    "    if (epoch % 500 == 0):\n",
    "        saver.save(sess, path+'/model_100/graphGRU_pre_%r'%epoch, global_step = epoch)\n",
    "\n",
    "time_end = time.time()\n",
    "print(time_end-time_start,'s')\n",
    "\n",
    "############## visualization ###############\n",
    "#x = [i for i in range(training_epoch)]\n",
    "b = int(len(batch_rmse)/totalbatch)\n",
    "batch_rmse1 = [i for i in batch_rmse]\n",
    "train_rmse = [(sum(batch_rmse1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "batch_loss1 = [i for i in batch_loss]\n",
    "train_loss = [(sum(batch_loss1[i*totalbatch:(i+1)*totalbatch])/totalbatch) for i in range(b)]\n",
    "#test_rmse = [float(i) for i in test_rmse]\n",
    "var = pd.DataFrame(batch_loss1)\n",
    "var.to_csv(path+'/batch_loss.csv',index = False,header = False)\n",
    "var = pd.DataFrame(train_loss)\n",
    "var.to_csv(path+'/train_loss.csv',index = False,header = False)\n",
    "var = pd.DataFrame(batch_rmse1)\n",
    "var.to_csv(path+'/batch_rmse.csv',index = False,header = False)\n",
    "var = pd.DataFrame(train_rmse)\n",
    "var.to_csv(path+'/train_rmse.csv',index = False,header = False)\n",
    "var = pd.DataFrame(test_loss)\n",
    "var.to_csv(path+'/test_loss.csv',index = False,header = False)\n",
    "var = pd.DataFrame(test_acc)\n",
    "var.to_csv(path+'/test_acc.csv',index = False,header = False)\n",
    "var = pd.DataFrame(test_rmse)\n",
    "var.to_csv(path+'/test_rmse.csv',index = False,header = False)\n",
    "\n",
    "\n",
    "index = test_rmse.index(np.min(test_rmse))\n",
    "test_result = test_pred[index]\n",
    "var = pd.DataFrame(test_result)\n",
    "var.to_csv(path+'/test_result.csv',index = False,header = False)\n",
    "plot_result(test_result,test_label1,path)\n",
    "plot_error(train_rmse,train_loss,test_rmse,test_acc,test_mae,path)\n",
    "\n",
    "fig1 = plt.figure(figsize=(7,3))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "plt.plot(np.sum(alpha1,0))\n",
    "plt.savefig(path+'/alpha.jpg',dpi=500)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.imshow(np.mat(np.sum(alpha1,0)))\n",
    "plt.savefig(path+'/alpha11.jpg',dpi=500)\n",
    "plt.show()\n",
    "\n",
    "print('min_rmse:%r'%(np.min(test_rmse)),\n",
    "      'min_mae:%r'%(test_mae[index]),\n",
    "      'max_acc:%r'%(test_acc[index]),\n",
    "      'r2:%r'%(test_r2[index]),\n",
    "      'var:%r'%test_var[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
